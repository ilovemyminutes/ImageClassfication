{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python377jvsc74a57bd098b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f",
   "display_name": "Python 3.7.7 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "sys.path.insert(0, '../')\n",
    "from dataset import TrainDataset\n",
    "from augmentation import configure_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV = 5\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = configure_transform('train', 'random')\n",
    "data_config = dict(root='../preprocessed/train', transform=transform, task='main', age_filter=58, meta_path='../preprocessed/metadata.json')\n",
    "dataset = TrainDataset(**data_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = SubsetRandomSampler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "15120 3780\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "sampler option is mutually exclusive with shuffle",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-13f0bf039101>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0msampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_sampler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mdrop_last\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         )\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msampler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             raise ValueError('sampler option is mutually exclusive with '\n\u001b[0m\u001b[1;32m    202\u001b[0m                              'shuffle')\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: sampler option is mutually exclusive with shuffle"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=CV, shuffle=True)\n",
    "\n",
    "for fold_idx, (train_idx_list, test_idx_list) in enumerate(kfold.split(dataset)):\n",
    "    print(len(train_idx_list), len(test_idx_list))\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(train_idx_list)\n",
    "    test_sampler = SubsetRandomSampler(test_idx_list)\n",
    "\n",
    "    trainloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        sampler=train_sampler,\n",
    "        drop_last=True,\n",
    "\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Old! 59 13\n",
      "Old! 60 5\n",
      "Old! 59 7\n",
      "Old! 59 1\n",
      "Old! 60 5\n",
      "Old! 60 2\n",
      "Old! 58 1\n",
      "Old! 58 4\n",
      "Old! 59 4\n",
      "Old! 58 4\n",
      "Old! 60 8\n",
      "Old! 59 10\n"
     ]
    }
   ],
   "source": [
    "for imgs, labels in trainloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([10,  1, 10, 14,  0,  7,  5,  9,  8,  0,  0, 16,  4,  2,  9,  4,  3,  3,\n",
       "         3,  5,  0,  1,  4, 10,  3,  6,  9,  3,  0, 15,  2,  6,  3, 15,  4,  3,\n",
       "         3,  2,  4, 12,  0,  5,  9,  0,  1, 15,  4,  3,  3,  4,  5,  5,  8,  0,\n",
       "         9,  1,  0,  0,  0,  4,  4,  1,  3, 11])"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "labels"
   ]
  }
 ]
}