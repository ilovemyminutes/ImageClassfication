{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "reasonable-pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from efficientnet_pytorch import EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "defensive-clarity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform configuration\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.2, 0.2, 0.2])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VanillaEfficientNet(nn.Module):\n",
    "    def __init__(self, n_class: int, freeze: bool = False):\n",
    "        super(VanillaEfficientNet, self).__init__()\n",
    "        self.efficientnet = EfficientNet.from_pretrained('efficientnet-b3')\n",
    "        if freeze:\n",
    "            self._freeze()\n",
    "        self.batchnorm = nn.BatchNorm1d(num_features=1000)\n",
    "        self.dropout = nn.Dropout()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear = nn.Linear(in_features=1000, out_features=n_class)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.efficientnet(x)\n",
    "        x = self.batchnorm(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(x)\n",
    "        output = self.linear(x)\n",
    "        return output\n",
    "\n",
    "    def _freeze(self):\n",
    "        for param in self.efficientnet.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loaded pretrained weights for efficientnet-b3\n"
     ]
    }
   ],
   "source": [
    "model = VanillaEfficientNet(18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 224, 224])"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "temp = torch.rand(4,3,224,224)\n",
    "temp.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 0.3997, -0.0692, -0.2884,  0.0105,  0.6515, -0.4172,  0.0310, -0.0247,\n",
       "         -0.9070, -1.1667,  0.5936, -0.9430,  0.3337,  0.1926, -1.6241, -0.8383,\n",
       "          0.5653, -0.2920],\n",
       "        [-0.0125,  0.6508, -0.3419,  0.1676, -0.8270, -0.5039, -0.4700,  0.8726,\n",
       "          0.0144,  0.1895, -0.1588, -0.0430, -0.6044, -0.7214, -0.2530,  0.2604,\n",
       "          0.2683,  0.1307],\n",
       "        [ 0.5126,  0.0911, -0.4083, -0.1728, -0.0151, -0.8613, -0.5094,  0.4684,\n",
       "          0.7996, -0.5260,  0.1693,  0.0774,  1.3813,  0.8344, -0.2808, -0.0481,\n",
       "         -0.0601,  0.2119],\n",
       "        [ 0.5763,  0.8501, -0.4600,  0.7922,  0.3319, -0.5993,  0.1242, -0.9275,\n",
       "         -0.3850,  0.1454,  0.9176, -0.4695, -0.3809,  1.0714, -0.4863, -1.0249,\n",
       "         -0.5567,  0.3002]], grad_fn=<AddmmBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "model(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.BatchNorm1d(100)\n",
    "m = nn.BatchNorm1d(100, affine=False)\n",
    "input = torch.randn(2, 100)\n",
    "output = m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "familiar-suspect",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple pretrained model\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Linear(512, 18)\n",
    "\n",
    "# freeze\n",
    "for name, param in model.named_parameters():\n",
    "    if name not in ['fc.weight', 'fc.bias']:\n",
    "        param.requires_grad = False # freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "adjacent-assist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train configuration\n",
    "EPOCHS = 3\n",
    "BATCH_SIZE = 64\n",
    "LR = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "external-appraisal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "aerial-theorem",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 885/885 [01:43<00:00,  8.54it/s]\n",
      "Train: 100%|██████████| 885/885 [01:43<00:00,  8.54it/s]\n",
      "Train: 100%|██████████| 885/885 [01:43<00:00,  8.54it/s]\n"
     ]
    }
   ],
   "source": [
    "# train phase\n",
    "model.cuda()\n",
    "model.train()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for imgs, labels in tqdm(loader, desc='Train'):\n",
    "        imgs = imgs.cuda()\n",
    "        labels = labels.cuda()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "entertaining-editor",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 178/178 [00:21<00:00,  8.38it/s]\n"
     ]
    }
   ],
   "source": [
    "# validation phase\n",
    "model.eval()\n",
    "\n",
    "total_corrects = 0\n",
    "total_samples = 0\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in tqdm(validloader, desc='Validation'):\n",
    "        imgs = imgs.cuda()\n",
    "        \n",
    "        outputs = model(imgs)\n",
    "        _, pred = torch.max(outputs, 1)\n",
    "        pred = pred.cpu().numpy()\n",
    "        labels = labels.cpu().numpy()\n",
    "        \n",
    "        total_corrects += (labels == pred).sum()\n",
    "        total_samples += len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ordered-catering",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7873\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy: {total_corrects/total_samples:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "chemical-tomato",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvalDataset(Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "        img_id_list = pd.read_csv('../input/data/eval/info.csv')['ImageID'] # to keep id order corresponding to that of submission\n",
    "        self.img_paths = list(map(lambda x: os.path.join('../input/data/eval/images', x), img_id_list))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        name = os.path.basename(self.img_paths[index]) # ImageID\n",
    "        image = Image.open(self.img_paths[index]) # image array\n",
    "        if self.transform:\n",
    "            image = self.transform(image) # transform(optional)\n",
    "        return name, image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "particular-prevention",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 197/197 [01:26<00:00,  2.27it/s]\n"
     ]
    }
   ],
   "source": [
    "# inference phase\n",
    "\n",
    "evalset = EvalDataset(transform)\n",
    "evalloader = DataLoader(evalset, batch_size=64, shuffle=False, drop_last=False)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "name_list = []\n",
    "pred_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for names, imgs in tqdm(evalloader):\n",
    "        imgs = imgs.cuda()\n",
    "        outputs = model(imgs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        pred_list.extend(preds.cpu().numpy().tolist())\n",
    "        name_list.extend(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "planned-bottle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Inference Size: 12600 12600\n"
     ]
    }
   ],
   "source": [
    "# check inference size\n",
    "if len(name_list) == len(pred_list):\n",
    "    print('Correct Inference Size:', len(name_list), len(pred_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "preliminary-polyester",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct ImageID Order\n"
     ]
    }
   ],
   "source": [
    "# check inference order\n",
    "submission_template = pd.read_csv('../input/data/eval/submission.csv')\n",
    "id_order = submission_template['ImageID'].tolist()\n",
    "\n",
    "allright = True\n",
    "for i, j in zip(id_order, name_list):\n",
    "    if i != j:\n",
    "        allright = False\n",
    "        print('Incorrect Order', i, j)\n",
    "\n",
    "if allright:\n",
    "    print('Correct ImageID Order')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "mechanical-infection",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compose submission\n",
    "submission = pd.DataFrame(dict(ImageID=name_list, ans=pred_list))\n",
    "submission.to_csv('submission_please.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python377jvsc74a57bd098b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f",
   "display_name": "Python 3.7.7 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}