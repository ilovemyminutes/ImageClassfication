{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "reasonable-pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from efficientnet_pytorch import EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "defensive-clarity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform configuration\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.2, 0.2, 0.2])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim.lr_scheduler.CosineAnnealingLR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loaded pretrained weights for efficientnet-b3\n"
     ]
    }
   ],
   "source": [
    "model = VanillaEfficientNet(18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 224, 224])"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "temp = torch.rand(4,3,224,224)\n",
    "temp.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([4, 18])"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "model(temp).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.BatchNorm1d(100)\n",
    "m = nn.BatchNorm1d(100, affine=False)\n",
    "input = torch.randn(2, 100)\n",
    "output = m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "familiar-suspect",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple pretrained model\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Linear(512, 18)\n",
    "\n",
    "# freeze\n",
    "for name, param in model.named_parameters():\n",
    "    if name not in ['fc.weight', 'fc.bias']:\n",
    "        param.requires_grad = False # freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "adjacent-assist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train configuration\n",
    "EPOCHS = 3\n",
    "BATCH_SIZE = 64\n",
    "LR = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "external-appraisal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "aerial-theorem",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 885/885 [01:43<00:00,  8.54it/s]\n",
      "Train: 100%|██████████| 885/885 [01:43<00:00,  8.54it/s]\n",
      "Train: 100%|██████████| 885/885 [01:43<00:00,  8.54it/s]\n"
     ]
    }
   ],
   "source": [
    "# train phase\n",
    "model.cuda()\n",
    "model.train()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for imgs, labels in tqdm(loader, desc='Train'):\n",
    "        imgs = imgs.cuda()\n",
    "        labels = labels.cuda()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "entertaining-editor",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 178/178 [00:21<00:00,  8.38it/s]\n"
     ]
    }
   ],
   "source": [
    "# validation phase\n",
    "model.eval()\n",
    "\n",
    "total_corrects = 0\n",
    "total_samples = 0\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in tqdm(validloader, desc='Validation'):\n",
    "        imgs = imgs.cuda()\n",
    "        \n",
    "        outputs = model(imgs)\n",
    "        _, pred = torch.max(outputs, 1)\n",
    "        pred = pred.cpu().numpy()\n",
    "        labels = labels.cpu().numpy()\n",
    "        \n",
    "        total_corrects += (labels == pred).sum()\n",
    "        total_samples += len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ordered-catering",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7873\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy: {total_corrects/total_samples:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "chemical-tomato",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvalDataset(Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "        img_id_list = pd.read_csv('../input/data/eval/info.csv')['ImageID'] # to keep id order corresponding to that of submission\n",
    "        self.img_paths = list(map(lambda x: os.path.join('../input/data/eval/images', x), img_id_list))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        name = os.path.basename(self.img_paths[index]) # ImageID\n",
    "        image = Image.open(self.img_paths[index]) # image array\n",
    "        if self.transform:\n",
    "            image = self.transform(image) # transform(optional)\n",
    "        return name, image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "particular-prevention",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 197/197 [01:26<00:00,  2.27it/s]\n"
     ]
    }
   ],
   "source": [
    "# inference phase\n",
    "\n",
    "evalset = EvalDataset(transform)\n",
    "evalloader = DataLoader(evalset, batch_size=64, shuffle=False, drop_last=False)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "name_list = []\n",
    "pred_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for names, imgs in tqdm(evalloader):\n",
    "        imgs = imgs.cuda()\n",
    "        outputs = model(imgs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        pred_list.extend(preds.cpu().numpy().tolist())\n",
    "        name_list.extend(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "planned-bottle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Inference Size: 12600 12600\n"
     ]
    }
   ],
   "source": [
    "# check inference size\n",
    "if len(name_list) == len(pred_list):\n",
    "    print('Correct Inference Size:', len(name_list), len(pred_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "preliminary-polyester",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct ImageID Order\n"
     ]
    }
   ],
   "source": [
    "# check inference order\n",
    "submission_template = pd.read_csv('../input/data/eval/submission.csv')\n",
    "id_order = submission_template['ImageID'].tolist()\n",
    "\n",
    "allright = True\n",
    "for i, j in zip(id_order, name_list):\n",
    "    if i != j:\n",
    "        allright = False\n",
    "        print('Incorrect Order', i, j)\n",
    "\n",
    "if allright:\n",
    "    print('Correct ImageID Order')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "mechanical-infection",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compose submission\n",
    "submission = pd.DataFrame(dict(ImageID=name_list, ans=pred_list))\n",
    "submission.to_csv('submission_please.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python377jvsc74a57bd098b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f",
   "display_name": "Python 3.7.7 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}