{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python377jvsc74a57bd098b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f",
   "display_name": "Python 3.7.7 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.nn import functional as F\n",
    "import torch\n",
    "\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "from inference import predict_submission\n",
    "from model import load_model\n",
    "from dataset import get_dataloader, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ageg = pd.read_csv('../prediction/all2021-04-07 162133/submission_ageg.csv')\n",
    "gender = pd.read_csv('../prediction/all2021-04-07 162133/submission_gender.csv')\n",
    "mask = pd.read_csv('../prediction/all2021-04-07 162133/submission_mask.csv')\n",
    "\n",
    "submission = pd.DataFrame(dict(ImageID=ageg['ImageID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['mask'] = mask['ans']\n",
    "submission['gender'] = gender['ans']\n",
    "submission['ageg'] = ageg['ans']\n",
    "enc = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission['ans'] = submission.apply(lambda x: enc.transform(tuple(x.iloc[1:]), task='main'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission[['ImageID', 'ans']].to_csv('submission_ens_enc.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "main.to_csv('submission_ens.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loaded pretrained weights for efficientnet-b3\n",
      "Inference:   0%|          | 0/3150 [00:00<?, ?it/s]Loaded pretrained weights from ../saved_models/mask/VanillaEfficientNet_task(mask)ep(09)f1(0.9845)bs(64)loss(0.0007)lr(0.005)trans(base)optim(adam)crit(labelsmoothingLoss)seed(42).pth\n",
      "Inference:   0%|          | 0/3150 [00:06<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "TASKS = ['mask', 'gender', 'ageg']\n",
    "CLASSES = {'mask':3, 'gender':2, 'ageg':3}\n",
    "WEIGHTS = {'mask':6, 'gender':3, 'ageg':1}\n",
    "\n",
    "param_dict = dict()\n",
    "param_dict['ageg'] = 'VanillaEfficientNet_task(ageg)ep(02)f1(0.8562)loss(0.0008)lr(0.001)trans(random)optim(adamp)crit(labelsmoothingLoss)seed(42).pth'\n",
    "param_dict['mask'] = 'VanillaEfficientNet_task(mask)ep(09)f1(0.9845)bs(64)loss(0.0007)lr(0.005)trans(base)optim(adam)crit(labelsmoothingLoss)seed(42).pth'\n",
    "param_dict['gender'] = 'VanillaEfficientNet_task(gender)ep(08)f1(0.9736)bs(32)loss(0.0006)lr(0.001)trans(random)optim(adamp)crit(labelsmoothingLoss)seed(42).pth'\n",
    "\n",
    "predictions = dict()\n",
    "\n",
    "for t in TASKS:\n",
    "    load_state_dict = os.path.join('../saved_models', t, param_dict[t])\n",
    "    model_type = param_dict[t].split('_')[0]\n",
    "    transform_type = param_dict[t].split('trans(')[-1].split(')')[0]\n",
    "    model = load_model(model_type=model_type, task=t, load_state_dict=load_state_dict)\n",
    "    model.cpu()\n",
    "    model.eval()\n",
    "\n",
    "    dataloader = get_dataloader(\n",
    "        task=t,\n",
    "        phase=\"eval\",\n",
    "        data_root='../input/data/eval/images',\n",
    "        transform_type=transform_type,\n",
    "        # batch_size=1024,\n",
    "        batch_size=4,\n",
    "        shuffle=False,\n",
    "        drop_last=False\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        id_list = []\n",
    "        pred_list = []\n",
    "\n",
    "        for img_ids, imgs in tqdm(dataloader, desc=\"Inference\"):\n",
    "            imgs = imgs.cpu()\n",
    "            output = model(imgs)\n",
    "            preds = F.softmax(output, dim=1)\n",
    "            pred_list.append(preds)\n",
    "            id_list.extend(img_ids)\n",
    "    \n",
    "    prediction = pd.DataFrame(np.vstack(pred_list))\n",
    "    prediction['ImageID'] = id_list\n",
    "\n",
    "    prediction.to_csv(\n",
    "        os.path.join(f\"prob_{t}.csv\"), index=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(4, 3)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "preds_np = preds.numpy()\n",
    "preds_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(8, 3)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "np.vstack([preds_np, preds_np]).shape"
   ]
  }
 ]
}