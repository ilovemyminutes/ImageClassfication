{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python377jvsc74a57bd098b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f",
   "display_name": "Python 3.7.7 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "sys.path.insert(0, '../')\n",
    "from dataset import TrainDataset\n",
    "from transform_settings import configure_transform\n",
    "from utils import load_json, set_seed\n",
    "from model import VanillaEfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = '../saved_models'\n",
    "\n",
    "load_gender = 'VanillaEfficientNet_taskgender_epoch02_lr0.005_transformbase_optimadam_loss0.0001_eval0.9658_seed42.pth'\n",
    "\n",
    "load_mask = 'VanillaEfficientNet_taskmask_epoch04_lr0.005_transformbase_optimadam_loss0.0000_eval0.9909_seed42.pth'\n",
    "\n",
    "load_ageg = 'VanillaEfficientNet_taskageg_epoch04_lr0.005_transformbase_optimadam_loss0.0002_eval0.9118_seed42.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loaded pretrained weights for efficientnet-b3\n",
      "Loaded pretrained weights for efficientnet-b3\n",
      "Loaded pretrained weights for efficientnet-b3\n"
     ]
    }
   ],
   "source": [
    "linear_gender = VanillaEfficientNet(n_class=2)\n",
    "linear_gender.load_state_dict(torch.load(os.path.join(SAVE_PATH, load_gender)))\n",
    "linear_gender = linear_gender.linear\n",
    "\n",
    "linear_mask = VanillaEfficientNet(n_class=3)\n",
    "linear_mask.load_state_dict(torch.load(os.path.join(SAVE_PATH, load_mask)))\n",
    "linear_mask = linear_mask.linear\n",
    "\n",
    "linear_ageg = VanillaEfficientNet(n_class=3)\n",
    "linear_ageg.load_state_dict(torch.load(os.path.join(SAVE_PATH, load_ageg)))\n",
    "linear_ageg = linear_ageg.linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Seed set as 42\n"
     ]
    }
   ],
   "source": [
    "ROOT = '../preprocessed/train'\n",
    "TASK = 'all'\n",
    "META = '../preprocessed/metadata.json'\n",
    "set_seed(42)\n",
    "transform = configure_transform('train', 'base')\n",
    "data = TrainDataset(ROOT, transform, TASK, META)\n",
    "loader = DataLoader(data, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imgs, labels in loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "class THAResNet_MK1(nn.Module): # Three-headed attention EfficientNEt\n",
    "    def __init__(self):\n",
    "        super(THAResNet_MK1, self).__init__()\n",
    "        self.backbone = models.resnet18(pretrained=True)\n",
    "        self.linear_mask = nn.Linear(1000, 3)\n",
    "        self.linear_ageg = nn.Linear(1000, 3)\n",
    "        self.linear_gender = nn.Linear(1000, 2)\n",
    "        self.linear_main = nn.Linear(1000, 18)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        output_mask = self.linear_mask(x)\n",
    "        output_ageg = self.linear_ageg(x)\n",
    "        output_gender = self.linear_gender(x)\n",
    "        output_main = self.linear_main(x)\n",
    "        return output_mask, output_ageg, output_gender, output_main\n",
    "\n",
    "    def _freeze(self):\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = THAResNet_MK1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_mask = optim.Adam(model.linear_mask.parameters(), lr=.005)\n",
    "optim_gender = optim.Adam(model.linear_gender.parameters(), lr=.005)\n",
    "optim_ageg = optim.Adam(model.linear_ageg.parameters(), lr=.005)\n",
    "optim_main = optim.Adam(model.parameters(), lr=.005)\n",
    "\n",
    "optim_mask_interaction = optim.Adam(list(model.backbone.parameters()) + list(model.linear_mask.parameters()), lr=.005)\n",
    "optim_ageg_interaction = optim.Adam(list(model.backbone.parameters()) + list(model.linear_ageg.parameters()), lr=.005)\n",
    "optim_gender_interaction = optim.Adam(list(model.backbone.parameters()) + list(model.linear_gender.parameters()), lr=.005)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_mask, output_ageg, output_gender, output_main = model(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_mask = criterion(output_mask, labels['mask'])\n",
    "loss_ageg = criterion(output_ageg, labels['ageg'])\n",
    "loss_gender = criterion(output_gender, labels['gender'])\n",
    "loss_main = criterion(output_main, labels['main'])\n",
    "\n",
    "loss_mask *= 0.375\n",
    "loss_ageg *= 0.375\n",
    "loss_gender *= 0.375\n",
    "loss_main *= .5\n",
    "\n",
    "loss_mask_interaction = criterion(output_mask, labels['mask'])\n",
    "loss_ageg_interaction = criterion(output_ageg, labels['ageg'])\n",
    "loss_gender_interaction = criterion(output_gender, labels['gender'])\n",
    "\n",
    "loss_mask_interaction *= 0.125\n",
    "loss_ageg_interaction *= 0.125\n",
    "loss_gender_interaction *= 0.125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_mask_interaction.backward(retain_graph=True)\n",
    "loss_ageg_interaction.backward(retain_graph=True)\n",
    "loss_gender_interaction.backward(retain_graph=True)\n",
    "\n",
    "loss_mask.backward(retain_graph=True)\n",
    "loss_ageg.backward(retain_graph=True)\n",
    "loss_gender.backward(retain_graph=True)\n",
    "loss_main.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_mask.step()\n",
    "optim_gender.step()\n",
    "optim_ageg.step()\n",
    "optim_main.step()\n",
    "optim_mask_interaction.step()\n",
    "optim_ageg_interaction.step()\n",
    "optim_gender_interaction.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}