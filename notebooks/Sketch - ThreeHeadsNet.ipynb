{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.7 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision import models\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "from dataset import TrainLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = '../preprocessed/train'\n",
    "TRANSFORM_TYPE = 'base'\n",
    "BATCH_SIZE = 16\n",
    "dataloader = TrainLoader(DATA_ROOT, TRANSFORM_TYPE, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = models.resnet101(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.fc = nn.Identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img, label in dataloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([16, 2048])"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "post_resnet = resnet(img)\n",
    "post_resnet.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "MASK_CLASSES = 3\n",
    "SEX_CLASSES = 2\n",
    "AGEG_CLASSES = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "def get_linear_dropout(in_features, out_features, p=.5):\n",
    "    layer = nn.Sequential(OrderedDict([\n",
    "        ('linear', nn.Linear(in_features=in_features, out_features=out_features)), \n",
    "        ('dropout', nn.Dropout(p=0.5))]))\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_mask = get_linear_dropout(in_features=2048, out_features=3)\n",
    "fc_sex = get_linear_dropout(in_features=2048, out_features=2)\n",
    "fc_ageg = get_linear_dropout(in_features=2048, out_features=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_layer = nn.ModuleList([fc_mask, fc_sex, fc_ageg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "for fc in fc_layer:\n",
    "    outputs.append(fc(post_resnet))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = torch.LongTensor([0 for _ in range(16)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(0.9253, grad_fn=<NllLossBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "F.cross_entropy(outputs[0], label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.ModuleList()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "conv1.weight\nbn1.weight\nbn1.bias\nlayer1.0.conv1.weight\nlayer1.0.bn1.weight\nlayer1.0.bn1.bias\nlayer1.0.conv2.weight\nlayer1.0.bn2.weight\nlayer1.0.bn2.bias\nlayer1.0.conv3.weight\nlayer1.0.bn3.weight\nlayer1.0.bn3.bias\nlayer1.0.downsample.0.weight\nlayer1.0.downsample.1.weight\nlayer1.0.downsample.1.bias\nlayer1.1.conv1.weight\nlayer1.1.bn1.weight\nlayer1.1.bn1.bias\nlayer1.1.conv2.weight\nlayer1.1.bn2.weight\nlayer1.1.bn2.bias\nlayer1.1.conv3.weight\nlayer1.1.bn3.weight\nlayer1.1.bn3.bias\nlayer1.2.conv1.weight\nlayer1.2.bn1.weight\nlayer1.2.bn1.bias\nlayer1.2.conv2.weight\nlayer1.2.bn2.weight\nlayer1.2.bn2.bias\nlayer1.2.conv3.weight\nlayer1.2.bn3.weight\nlayer1.2.bn3.bias\nlayer2.0.conv1.weight\nlayer2.0.bn1.weight\nlayer2.0.bn1.bias\nlayer2.0.conv2.weight\nlayer2.0.bn2.weight\nlayer2.0.bn2.bias\nlayer2.0.conv3.weight\nlayer2.0.bn3.weight\nlayer2.0.bn3.bias\nlayer2.0.downsample.0.weight\nlayer2.0.downsample.1.weight\nlayer2.0.downsample.1.bias\nlayer2.1.conv1.weight\nlayer2.1.bn1.weight\nlayer2.1.bn1.bias\nlayer2.1.conv2.weight\nlayer2.1.bn2.weight\nlayer2.1.bn2.bias\nlayer2.1.conv3.weight\nlayer2.1.bn3.weight\nlayer2.1.bn3.bias\nlayer2.2.conv1.weight\nlayer2.2.bn1.weight\nlayer2.2.bn1.bias\nlayer2.2.conv2.weight\nlayer2.2.bn2.weight\nlayer2.2.bn2.bias\nlayer2.2.conv3.weight\nlayer2.2.bn3.weight\nlayer2.2.bn3.bias\nlayer2.3.conv1.weight\nlayer2.3.bn1.weight\nlayer2.3.bn1.bias\nlayer2.3.conv2.weight\nlayer2.3.bn2.weight\nlayer2.3.bn2.bias\nlayer2.3.conv3.weight\nlayer2.3.bn3.weight\nlayer2.3.bn3.bias\nlayer3.0.conv1.weight\nlayer3.0.bn1.weight\nlayer3.0.bn1.bias\nlayer3.0.conv2.weight\nlayer3.0.bn2.weight\nlayer3.0.bn2.bias\nlayer3.0.conv3.weight\nlayer3.0.bn3.weight\nlayer3.0.bn3.bias\nlayer3.0.downsample.0.weight\nlayer3.0.downsample.1.weight\nlayer3.0.downsample.1.bias\nlayer3.1.conv1.weight\nlayer3.1.bn1.weight\nlayer3.1.bn1.bias\nlayer3.1.conv2.weight\nlayer3.1.bn2.weight\nlayer3.1.bn2.bias\nlayer3.1.conv3.weight\nlayer3.1.bn3.weight\nlayer3.1.bn3.bias\nlayer3.2.conv1.weight\nlayer3.2.bn1.weight\nlayer3.2.bn1.bias\nlayer3.2.conv2.weight\nlayer3.2.bn2.weight\nlayer3.2.bn2.bias\nlayer3.2.conv3.weight\nlayer3.2.bn3.weight\nlayer3.2.bn3.bias\nlayer3.3.conv1.weight\nlayer3.3.bn1.weight\nlayer3.3.bn1.bias\nlayer3.3.conv2.weight\nlayer3.3.bn2.weight\nlayer3.3.bn2.bias\nlayer3.3.conv3.weight\nlayer3.3.bn3.weight\nlayer3.3.bn3.bias\nlayer3.4.conv1.weight\nlayer3.4.bn1.weight\nlayer3.4.bn1.bias\nlayer3.4.conv2.weight\nlayer3.4.bn2.weight\nlayer3.4.bn2.bias\nlayer3.4.conv3.weight\nlayer3.4.bn3.weight\nlayer3.4.bn3.bias\nlayer3.5.conv1.weight\nlayer3.5.bn1.weight\nlayer3.5.bn1.bias\nlayer3.5.conv2.weight\nlayer3.5.bn2.weight\nlayer3.5.bn2.bias\nlayer3.5.conv3.weight\nlayer3.5.bn3.weight\nlayer3.5.bn3.bias\nlayer3.6.conv1.weight\nlayer3.6.bn1.weight\nlayer3.6.bn1.bias\nlayer3.6.conv2.weight\nlayer3.6.bn2.weight\nlayer3.6.bn2.bias\nlayer3.6.conv3.weight\nlayer3.6.bn3.weight\nlayer3.6.bn3.bias\nlayer3.7.conv1.weight\nlayer3.7.bn1.weight\nlayer3.7.bn1.bias\nlayer3.7.conv2.weight\nlayer3.7.bn2.weight\nlayer3.7.bn2.bias\nlayer3.7.conv3.weight\nlayer3.7.bn3.weight\nlayer3.7.bn3.bias\nlayer3.8.conv1.weight\nlayer3.8.bn1.weight\nlayer3.8.bn1.bias\nlayer3.8.conv2.weight\nlayer3.8.bn2.weight\nlayer3.8.bn2.bias\nlayer3.8.conv3.weight\nlayer3.8.bn3.weight\nlayer3.8.bn3.bias\nlayer3.9.conv1.weight\nlayer3.9.bn1.weight\nlayer3.9.bn1.bias\nlayer3.9.conv2.weight\nlayer3.9.bn2.weight\nlayer3.9.bn2.bias\nlayer3.9.conv3.weight\nlayer3.9.bn3.weight\nlayer3.9.bn3.bias\nlayer3.10.conv1.weight\nlayer3.10.bn1.weight\nlayer3.10.bn1.bias\nlayer3.10.conv2.weight\nlayer3.10.bn2.weight\nlayer3.10.bn2.bias\nlayer3.10.conv3.weight\nlayer3.10.bn3.weight\nlayer3.10.bn3.bias\nlayer3.11.conv1.weight\nlayer3.11.bn1.weight\nlayer3.11.bn1.bias\nlayer3.11.conv2.weight\nlayer3.11.bn2.weight\nlayer3.11.bn2.bias\nlayer3.11.conv3.weight\nlayer3.11.bn3.weight\nlayer3.11.bn3.bias\nlayer3.12.conv1.weight\nlayer3.12.bn1.weight\nlayer3.12.bn1.bias\nlayer3.12.conv2.weight\nlayer3.12.bn2.weight\nlayer3.12.bn2.bias\nlayer3.12.conv3.weight\nlayer3.12.bn3.weight\nlayer3.12.bn3.bias\nlayer3.13.conv1.weight\nlayer3.13.bn1.weight\nlayer3.13.bn1.bias\nlayer3.13.conv2.weight\nlayer3.13.bn2.weight\nlayer3.13.bn2.bias\nlayer3.13.conv3.weight\nlayer3.13.bn3.weight\nlayer3.13.bn3.bias\nlayer3.14.conv1.weight\nlayer3.14.bn1.weight\nlayer3.14.bn1.bias\nlayer3.14.conv2.weight\nlayer3.14.bn2.weight\nlayer3.14.bn2.bias\nlayer3.14.conv3.weight\nlayer3.14.bn3.weight\nlayer3.14.bn3.bias\nlayer3.15.conv1.weight\nlayer3.15.bn1.weight\nlayer3.15.bn1.bias\nlayer3.15.conv2.weight\nlayer3.15.bn2.weight\nlayer3.15.bn2.bias\nlayer3.15.conv3.weight\nlayer3.15.bn3.weight\nlayer3.15.bn3.bias\nlayer3.16.conv1.weight\nlayer3.16.bn1.weight\nlayer3.16.bn1.bias\nlayer3.16.conv2.weight\nlayer3.16.bn2.weight\nlayer3.16.bn2.bias\nlayer3.16.conv3.weight\nlayer3.16.bn3.weight\nlayer3.16.bn3.bias\nlayer3.17.conv1.weight\nlayer3.17.bn1.weight\nlayer3.17.bn1.bias\nlayer3.17.conv2.weight\nlayer3.17.bn2.weight\nlayer3.17.bn2.bias\nlayer3.17.conv3.weight\nlayer3.17.bn3.weight\nlayer3.17.bn3.bias\nlayer3.18.conv1.weight\nlayer3.18.bn1.weight\nlayer3.18.bn1.bias\nlayer3.18.conv2.weight\nlayer3.18.bn2.weight\nlayer3.18.bn2.bias\nlayer3.18.conv3.weight\nlayer3.18.bn3.weight\nlayer3.18.bn3.bias\nlayer3.19.conv1.weight\nlayer3.19.bn1.weight\nlayer3.19.bn1.bias\nlayer3.19.conv2.weight\nlayer3.19.bn2.weight\nlayer3.19.bn2.bias\nlayer3.19.conv3.weight\nlayer3.19.bn3.weight\nlayer3.19.bn3.bias\nlayer3.20.conv1.weight\nlayer3.20.bn1.weight\nlayer3.20.bn1.bias\nlayer3.20.conv2.weight\nlayer3.20.bn2.weight\nlayer3.20.bn2.bias\nlayer3.20.conv3.weight\nlayer3.20.bn3.weight\nlayer3.20.bn3.bias\nlayer3.21.conv1.weight\nlayer3.21.bn1.weight\nlayer3.21.bn1.bias\nlayer3.21.conv2.weight\nlayer3.21.bn2.weight\nlayer3.21.bn2.bias\nlayer3.21.conv3.weight\nlayer3.21.bn3.weight\nlayer3.21.bn3.bias\nlayer3.22.conv1.weight\nlayer3.22.bn1.weight\nlayer3.22.bn1.bias\nlayer3.22.conv2.weight\nlayer3.22.bn2.weight\nlayer3.22.bn2.bias\nlayer3.22.conv3.weight\nlayer3.22.bn3.weight\nlayer3.22.bn3.bias\nlayer4.0.conv1.weight\nlayer4.0.bn1.weight\nlayer4.0.bn1.bias\nlayer4.0.conv2.weight\nlayer4.0.bn2.weight\nlayer4.0.bn2.bias\nlayer4.0.conv3.weight\nlayer4.0.bn3.weight\nlayer4.0.bn3.bias\nlayer4.0.downsample.0.weight\nlayer4.0.downsample.1.weight\nlayer4.0.downsample.1.bias\nlayer4.1.conv1.weight\nlayer4.1.bn1.weight\nlayer4.1.bn1.bias\nlayer4.1.conv2.weight\nlayer4.1.bn2.weight\nlayer4.1.bn2.bias\nlayer4.1.conv3.weight\nlayer4.1.bn3.weight\nlayer4.1.bn3.bias\nlayer4.2.conv1.weight\nlayer4.2.bn1.weight\nlayer4.2.bn1.bias\nlayer4.2.conv2.weight\nlayer4.2.bn2.weight\nlayer4.2.bn2.bias\nlayer4.2.conv3.weight\nlayer4.2.bn3.weight\nlayer4.2.bn3.bias\nfc.weight\nfc.bias\n"
     ]
    }
   ],
   "source": [
    "for name, parameter in resnet.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}